<source>
  @type systemd
  path /var/log/journal
  tag journal
  <entry>
    fields_strip_underscores true
    fields_lowercase true
  </entry>
</source>
# system-fluentd config
# drop fluentd logs
<match fluent.**>
  @type null
</match>

# read logs from k8s containers
<source>
  @type tail
  path /var/log/containers/*.log
  read_from_head true
  pos_file /var/log/fluentd-container-log.pos
  time_format %Y-%m-%dT%H:%M:%S
  tag kubernetes.*
  format json
</source>


# if you want to enable ssl of prometheus uncomment following line. And add corresponding match. Do not change the path of certificates.
<source>
  @type prometheus
  ##uncomment below line "bind" in IPv6 Env
  #bind ::
#  <ssl>
#   enable true
#   certificate_path "/etc/td-agent/certs/prometheus-crt.pem"
#   private_key_path "/etc/td-agent/certs/prometheus-key.pem"
#   ca_path "/etc/td-agent/certs/prometheus-root-ca.pem"
#  </ssl>
</source>

<source>
  @type monitor_agent
</source>

<source>
  @type forward
</source>

# input plugin that collects metrics from MonitorAgent
<source>
 @type prometheus_monitor
  <labels>
    host ${hostname}
  </labels>
</source>

# input plugin that collects metrics for output plugin
<source>
  @type prometheus_output_monitor
  <labels>
    host ${hostname}
  </labels>
</source>

# input plugin that collects metrics for in_tail plugin
<source>
  @type prometheus_tail_monitor
  <labels>
    host ${hostname}
  </labels>
</source>

# parse logs using kubernetes_metadata filter
<filter kubernetes.**>
  @type kubernetes_metadata
  ##Setting kubernetes_url with service name since URL encoding does not work correctly with IPv6 addresses
  # The format is https://<kubernetes-service-name>.<namespace>.svc:<kubernetes-service-port>
  kubernetes_url https://kubernetes.default.svc:443
</filter>

# rewrite_tag_filter does not support nested fields like
# kubernetes.container_name, so this exists to flatten the fields
# and use them in rewrite_tag_filter
<filter kubernetes.**>
  @type record_transformer
  enable_ruby true
  <record>
    pod-name ${record["kubernetes"]["pod_name"]}
    namespace ${record["kubernetes"]["namespace_name"]}
    tenant_msgtype ${record["kubernetes"]["namespace_name"]}.${record["type"]}
  </record>
</filter>

# retag based on the container name of the log message
<match kubernetes.**>
  @type rewrite_tag_filter
  <rule>
    key tenant_msgtype
    pattern ^(.+)$
    tag nokia.logging.$1
  </rule>
</match>

# remove the unnecessary field as the information is already available on other fields.
<filter nokia.logging.**>
  @type record_transformer
  remove_keys tenant_msgtype
</filter>

# do not forward kube-system logs as k8s generates a lot of logs
<match nokia.logging.kube-system.**>
  @type null
</match>

# forward all tenants logs to public elasticsearch
# do not split per type now as standard k8s logs do not have type
<match nokia.logging.**>
  @type elasticsearch_dynamic
  @log_level info
  include_tag_key true
  #host is the elasticsearch service name.
  #If you have created certificates in perticular namespace then use host as elasticsearch.<namespace> while using SG.
  host elasticsearch
  port 9200
  #Below commented lines are ssl properties.Please uncomment below commented lines from user to ca_file when you want to use.
  #user admin
  #password admin
  #scheme https
  #ssl_verify true
  #ssl_version TLSv1_2
  ##use the same certificate name configured in values.yaml.
  ##Donot change the certificate path since it is mounted by default in this path.
  #ca_file /etc/td-agent/certs/es-root-ca.pem
  logstash_format true
  logstash_prefix log-${tag_parts[2]}
</match>

# sending all journal logs to elasticsearch.
<match journal.**>
  @type elasticsearch
  @log_level info
  include_tag_key true
  #host is the elasticsearch service name.
  #If you have created certificates in perticular namespace then use host as elasticsearch.<namespace> while using SG.
  host elasticsearch
  port 9200
  #Below commented lines are ssl properties.Please uncomment below commented lines from user to ca_file when you want to use
  #user admin
  #password admin
  #scheme https
  #ssl_verify true
  #ssl_version TLSv1_2
  ##use the same certificate name configured in values.yaml.
  ##Donot change the certificate path since it is mounted by default in this path.
  #ca_file /etc/td-agent/certs/es-root-ca.pem
  logstash_format true
  logstash_prefix journal
</match>

